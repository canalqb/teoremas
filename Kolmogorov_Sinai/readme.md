# üîê - Teorema de Kolmogorov‚ÄìSinai

## Frase do Teorema

> A entropia de um sistema din√¢mico mede a **quantidade m√°xima de informa√ß√£o** (ou aleatoriedade) que ele gera com o tempo ‚Äì ou seja, o grau de **imprevisibilidade** do seu comportamento.

---

## Sum√°rio

* [1. Introdu√ß√£o ao Teorema](#1-introdu√ß√£o-ao-teorema)
  * [1.1 Resumo](#11-resumo)
  * [1.2 Exemplos Pr√°ticos](#12-exemplos-pr√°ticos)
  * [1.3 Explica√ß√£o Detalhada](#13-explica√ß√£o-detalhada)
  * [1.4 Aplica√ß√µes](#14-aplica√ß√µes)
  * [1.5 An√°lise da Tabela](#15-an√°lise-da-tabela)
* [2. Script `Kolmogorov_Sinai.py`](#2-script-kolmogorov_sinaipy)
  * [2.1 Rela√ß√£o com o Teorema](#21-rela√ß√£o-com-o-teorema)
  * [2.2 Objetivo do Script](#22-objetivo-do-script)
  * [2.3 Exemplo de Sa√≠da](#23-exemplo-de-sa√≠da)
  * [2.4 Funcionamento Interno](#24-funcionamento-interno)
  * [2.5 Tecnologias e Requisitos](#25-tecnologias-e-requisitos)
* [3 Extras](#3-extras)
  * [3.1 Licen√ßa](#31-licen√ßa)
  * [3.2 Refer√™ncias](#32-referencias)
  * [3.3 Testes e Valida√ß√µes](#33-testes-e-valida√ß√µes)
* [4 Contato](#4-contato)
* [5. Nota](#5-nota)

---

## 1. Introdu√ß√£o ao Teorema

### 1.1 Resumo

O **Teorema de Kolmogorov‚ÄìSinai** √© um pilar da **teoria erg√≥dica** e da **teoria da informa√ß√£o**. Ele permite medir o quanto um sistema din√¢mico √© **aleat√≥rio** ou **informativo** com o passar do tempo.

Se observarmos uma sequ√™ncia de dados (como 0s e 1s), esse teorema nos ajuda a entender **quanta informa√ß√£o nova aparece a cada passo**.

### 1.2 Exemplos Pr√°ticos

- Avaliar a aleatoriedade de geradores de n√∫meros bin√°rios
- Medir o conte√∫do de informa√ß√£o em sensores ou sinais digitais
- Detectar padr√µes escondidos em fluxos de dados

### 1.3 Explica√ß√£o Detalhada

Imagine uma longa sequ√™ncia de bits como:

```
011010001011...

```

Dividimos essa sequ√™ncia em **blocos de tamanho k** (por exemplo, blocos de 2 bits: 01, 10, 00, ...), e medimos a **diversidade** desses blocos. Se todos aparecem com a mesma frequ√™ncia, temos **alta entropia**.

A entropia por bit √© definida como:

```
h = limite de H\_k / k, quando k vai para o infinito

```

Onde:

- `H_k` √© a entropia total dos blocos de tamanho `k`
- `k` √© o tamanho do bloco

Quanto mais pr√≥ximo de **1.0** estiver `H_k / k`, mais aleat√≥ria √© a sequ√™ncia.

### 1.4 Aplica√ß√µes

- Avaliar se uma fonte de dados √© criptograficamente segura
- Medir compressibilidade de arquivos
- Detectar redund√¢ncia em transmiss√µes
- Estudar o comportamento ca√≥tico de sistemas complexos

### 1.5 An√°lise da Tabela

O script mostra como a entropia cresce com o tamanho dos blocos `k`.  
Exemplo de sa√≠da:

```
| k | Blocos √∫nicos | Total blocos | H\_k (bits) | H\_k / k |
| - | ------------- | ------------ | ----------- | -------- |
| 1 | 2             | 100000       | 1.000000    | 1.0000   |
| 2 | 4             | 50000        | 2.000000    | 1.0000   |
| 3 | 8             | 33333        | 3.000000    | 1.0000   |

```

Blocos totalmente aleat√≥rios ocupam **todos os padr√µes poss√≠veis** (2^k).  
Se isso acontece, o valor `H_k / k` tende a **1.0**, que √© o valor m√°ximo de entropia por bit.

---

## 2. Script `Kolmogorov_Sinai.py`

### 2.1 Rela√ß√£o com o Teorema

Este script mostra como calcular a entropia de uma sequ√™ncia bin√°ria com base no Teorema de Kolmogorov‚ÄìSinai. Ele verifica **quantos padr√µes √∫nicos existem** √† medida que o tamanho dos blocos aumenta.

### 2.2 Objetivo do Script

- Gerar uma sequ√™ncia bin√°ria segura e aleat√≥ria
- Dividir essa sequ√™ncia em blocos de tamanho `k`
- Calcular a **entropia de Shannon** desses blocos
- Mostrar a **entropia por bit** (H_k / k)
- Permitir an√°lise de aleatoriedade de forma pr√°tica

### 2.3 Exemplo de Sa√≠da

üìä An√°lise de Entropia com base em Kolmogorov‚ÄìSinai
Total de bits gerados: 100000
Fonte: secrets.token\_bytes

```
| k | Blocos √∫nicos | Total blocos | H\_k (bits) | H\_k / k |
| - | ------------- | ------------ | ----------- | -------- |
| 1 | 2             | 100000       | 1.000000    | 1.0000   |
| 2 | 4             | 50000        | 2.000000    | 1.0000   |
| 3 | 8             | 33333        | 3.000000    | 1.0000   |

```

### 2.4 Funcionamento Interno

O script:

1. Gera uma sequ√™ncia bin√°ria com `secrets.token_bytes`
2. Converte os bytes em bits (0s e 1s)
3. Para cada valor de `k`, forma blocos consecutivos
4. Conta as ocorr√™ncias de cada bloco
5. Calcula a entropia `H_k` usando a f√≥rmula de Shannon
6. Exibe a entropia total e a entropia por bit (`H_k / k`)

### 2.5 Tecnologias e Requisitos

- **Python 3.8.10**
- Bibliotecas utilizadas:
  - `secrets`
  - `math`
  - `collections`

Instala√ß√£o:

Nenhuma instala√ß√£o externa √© necess√°ria. Tudo funciona com bibliotecas padr√£o do Python.

---

## 3 Extras

### 3.1 Licen√ßa

Este projeto √© **open source** sob a licen√ßa **MIT**.  
Use, compartilhe e modifique livremente!

### 3.2 Refer√™ncias

- A.N. Kolmogorov ‚Äî *Entropy per Unit Time as a Metric Invariant of Automorphisms*
- C.E. Shannon ‚Äî *A Mathematical Theory of Communication*
- Cover & Thomas ‚Äî *Elements of Information Theory*

### 3.3 Testes e Valida√ß√µes

- O script foi testado com diferentes valores de `n_bits` e `k_max`
- A entropia por bit aproxima-se de 1.0 em fontes verdadeiramente aleat√≥rias
- O c√≥digo foi validado com sequ√™ncias artificiais e reais

---

## 4 Contato

* Feito por **CanalQb** no GitHub  
* Visite o blog: [canalqb.blogspot.com](https://canalqb.blogspot.com)  
* üí∏ Apoie o projeto via Bitcoin: `13Ve1k5ivByaCQ5yer6GoV84wAtf3kNava`  
* PIX: [qrodrigob@gmail.com](mailto:qrodrigob@gmail.com)

_Readme.md corrigido por ChatGPT_

---

## 5. Nota

### Termos T√©cnicos Explicados

- **Entropia**: medida de incerteza ou quantidade de informa√ß√£o em uma fonte de dados.
- **Entropia por bit (H_k / k)**: valor m√©dio de incerteza de cada bit na sequ√™ncia.
- **Shannon**: criador da teoria da informa√ß√£o, que define como medir a entropia.
- **Teoria erg√≥dica**: √°rea da matem√°tica que estuda como sistemas evoluem com o tempo.
- **Aleatoriedade criptogr√°fica**: gera√ß√£o de n√∫meros imprevis√≠veis, mesmo para um atacante que conhece o sistema.
- **Blocos de k bits**: grupos de bits consecutivos usados para calcular padr√µes e medir a entropia.
- **Fonte de informa√ß√£o**: qualquer sequ√™ncia de dados ou sinais que transmite algo com o tempo.

---
